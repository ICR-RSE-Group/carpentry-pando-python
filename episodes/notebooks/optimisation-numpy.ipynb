{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1cbecd-8d60-4579-9a50-53b143c39c54",
   "metadata": {},
   "source": [
    "# Using pandas and numpy effectively\n",
    "Both pandas and numpy have been written in Compiled languages, mostly C: \n",
    "### NumPy\n",
    "\n",
    "* The core array operations (like vectorised math, broadcasting, slicing, etc.) are implemented in C (and some Fortran, especially for linear algebra via BLAS/LAPACK).\n",
    "\n",
    "* The Python layer is mostly a wrapper that calls into these fast C routines.\n",
    "\n",
    "That’s why NumPy is so much faster than plain Python loops.\n",
    "\n",
    "### pandas\n",
    "\n",
    "* Built on top of NumPy, so it inherits a lot of that C speed indirectly.\n",
    "\n",
    "* Performance-critical parts (like groupby, joins, parsing CSVs) are written in C or Cython (a Python-like language that compiles to C).\n",
    "\n",
    "* The higher-level DataFrame/Series API is written in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05cb503-a144-4fb5-bdbc-81dd26938110",
   "metadata": {},
   "source": [
    "# Using Numpy (efficiently) :\n",
    "1. ## Numpy arrays are static:\n",
    "* They are fixed in size (unlike Python lists).\n",
    "\n",
    "* They don’t automatically resize when you add elements.\n",
    "\n",
    "* To append, you must call `resize()` explicitly.\n",
    "\n",
    "* Resizing on every append causes `many extra copies and memory allocations`.\n",
    "\n",
    "* This makes repeated appends much slower than using Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff046953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_append: 1.22ms\n",
      "array_resize: 12.60ms\n"
     ]
    }
   ],
   "source": [
    "# show casing the drawback of resizing a numpy array\n",
    "from timeit import timeit\n",
    "import numpy\n",
    "\n",
    "N = 100000  # Number of elements in list/array\n",
    "\n",
    "def list_append():\n",
    "    ls = []\n",
    "    for i in range(N):\n",
    "        ls.append(i)\n",
    "\n",
    "def array_resize():\n",
    "    ar = numpy.zeros(1)\n",
    "    for i in range(1, N):\n",
    "        ar.resize(i+1)\n",
    "        ar[i] = i\n",
    "        \n",
    "repeats = 1000\n",
    "print(f\"list_append: {timeit(list_append, number=repeats):.2f}ms\")\n",
    "print(f\"array_resize: {timeit(array_resize, number=repeats):.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fba2a-bf85-473f-a1a3-1390398b514e",
   "metadata": {},
   "source": [
    "### Conclusion 1: Avoid trying to resize Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9e449-6ab6-4902-aa31-fadb518104e7",
   "metadata": {},
   "source": [
    "## 2. NumPy arrays typically require all data to be the `same type` (and a NumPy type)\n",
    "\n",
    "If you don't respect this, you lose the advantages from using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438b3607-2cf9-49f2-8d15-e61f8afe818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'float'> <class 'int'> <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.5, 5])\n",
    "print(type(a[0]))\n",
    "print(type(a[1]))\n",
    "\n",
    "b = np.array([0.5, 5,{\"foo\":5}])\n",
    "print(type(b[0]),type(b[1]),type(b[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e3aa8-592c-4642-85cd-4aaf33ba10e0",
   "metadata": {},
   "source": [
    "## We will demonstrate now the overhead from mixing Python lists and NumPy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d6a85b-f1f6-4773-be75-f8029e5746e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: Time for 1000 runs: 0.5479201669950271 seconds\n",
      "Numpy: Time for 1000 runs: 0.0032690829975763336 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "#python list\n",
    "ls = list(range(10000))\n",
    "time = timeit.timeit(lambda: np.random.choice(ls), number=1000)\n",
    "print(\"List: Time for 1000 runs:\", time, \"seconds\")\n",
    "\n",
    "# NumPy array, numpy.random.choice()\n",
    "ar = numpy.arange(10000)\n",
    "time = timeit.timeit(lambda: np.random.choice(ar), number=1000)\n",
    "print(\"Numpy: Time for 1000 runs:\", time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9464b-acff-493b-ab91-d3ff9166ed3b",
   "metadata": {},
   "source": [
    "### Conclusion: Passing a Python list to numpy.random.choice() is 65.6x slower than passing a NumPy array. \n",
    "This is the additional overhead of converting the list to an array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a0be1-384a-4944-ab4e-779cfc6f08f1",
   "metadata": {},
   "source": [
    "# Numpy and array broadcasting\n",
    "* NumPy arrays support `broadcasting` many mathematical operations or functions. \n",
    "\n",
    "* This is a shorthand notation, where the operation/function is applied `element-wise` without having to loop over the array explicitly\n",
    "\n",
    "* No need to loop over array, thus optimising the code!\n",
    "\n",
    "* This means also that multiple `operations could be applied simultaneously`, rather than sequentially --> significant performance boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14628c7-c226-4c32-902f-b54cc1dd8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "[10 11 12 13 14 15]\n",
      "[ 0  2  4  6  8 10]\n",
      "[ 0  1  4  9 16 25]\n",
      "[  1.           2.71828183   7.3890561   20.08553692  54.59815003\n",
      " 148.4131591 ]\n",
      "[ 1  3  5  7  9 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ar = np.arange(6)\n",
    "print(ar)\n",
    "print(ar + 10)\n",
    "print(ar * 2)\n",
    "print(ar**2)\n",
    "print(np.exp(ar))\n",
    "print(ar*2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a23beb-4514-499d-8670-b13e0e278b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m lt = [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(lt*\u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlt\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m2\u001b[39;49m)\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "# lists do not allow broadcasting\n",
    "lt = [0, 1, 2, 3, 4, 5]\n",
    "print(lt*2)\n",
    "print(lt+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3add66b-f330-4049-9f39-f904bed8b532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array size 1: 0.418775 seconds total\n",
      "Array size 10: 0.381499 seconds total\n",
      "Array size 100: 0.396316 seconds total\n",
      "List size 1: 0.090674 seconds total\n",
      "List size 10: 0.193455 seconds total\n",
      "List size 100: 1.267181 seconds total\n"
     ]
    }
   ],
   "source": [
    "# speed of applying broadcasting is independent from the size of the numpy arrays (comparing to using lists)\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "for n in [1, 10, 100]:\n",
    "    ar = np.arange(n)\n",
    "    time = timeit.timeit(lambda: ar + 10, number=1_000_000)\n",
    "    print(f\"Array size {n}: {time:.6f} seconds total\")\n",
    "\n",
    "\n",
    "for n in [1, 10, 100]:\n",
    "    ls = list(range(n))\n",
    "    time = timeit.timeit(lambda: [x + 10 for x in ls], number=1_000_000)\n",
    "    print(f\"List size {n}: {time:.6f} seconds total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27b194a9-f740-4add-8579-f73350e3f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A final summary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614a7d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_sum_list: 21.83ms\n",
      "python_sum_array: 30.91ms\n",
      "numpy_sum_array: 0.57ms\n",
      "numpy_dot_array: 0.27ms\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "N = 1000000  # Number of elements in list\n",
    "\n",
    "gen_list = f\"ls = list(range({N}))\"\n",
    "gen_array = f\"import numpy; ar = numpy.arange({N}, dtype=numpy.int64)\"\n",
    "\n",
    "py_sum_ls = \"sum([i*i for i in ls])\"\n",
    "py_sum_ar = \"sum(ar*ar)\"\n",
    "np_sum_ar = \"numpy.sum(ar*ar)\"\n",
    "np_dot_ar = \"numpy.dot(ar, ar)\"\n",
    "\n",
    "repeats = 1000\n",
    "print(f\"python_sum_list: {timeit(py_sum_ls, setup=gen_list, number=repeats):.2f}ms\")\n",
    "print(f\"python_sum_array: {timeit(py_sum_ar, setup=gen_array, number=repeats):.2f}ms\")\n",
    "\n",
    "print(f\"numpy_sum_array: {timeit(np_sum_ar, setup=gen_array, number=repeats):.2f}ms\")\n",
    "print(f\"numpy_dot_array: {timeit(np_dot_ar, setup=gen_array, number=repeats):.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f46509-d38e-41ec-862d-ec0cdac291c9",
   "metadata": {},
   "source": [
    "# Pandas :\n",
    "* Pandas is the most common Python package when working with tabular data (`csv`, `tsv` files).\n",
    "* Pandas enhances performance if used well, otherwise it can harm performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae97eea-c5e3-4bdd-b235-a52c27717487",
   "metadata": {},
   "source": [
    "## Pandas methods by default operate on `columns`\n",
    "* This means that elements of a same column are saved in the same memory space.\n",
    "* Think of the column as a numpy array, highly suitable for vectorisation.\n",
    "\n",
    "* Iterating over DataFrame rows using a Python for loop is slow and not recommended!\n",
    "\n",
    "* Prefer Pandas built-in methods that support axis=1 for row-wise operations.\n",
    "\n",
    "* If no built-in method exists, use `apply()` to apply a custom function to rows (similar to `map()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6e557eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_range: 747.98ms\n",
      "for_iterrows: 852.20ms\n",
      "pandas_apply: 235.65ms\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "N = 100000  # Number of rows in DataFrame\n",
    "\n",
    "def genDataFrame():\n",
    "    numpy.random.seed(12)  # Ensure each dataframe is identical\n",
    "    return pandas.DataFrame(\n",
    "    {\n",
    "        \"f_vertical\": numpy.random.random(size=N),\n",
    "        \"f_horizontal\": numpy.random.random(size=N),\n",
    "        # todo some spurious columns\n",
    "    })\n",
    "\n",
    "def pythagoras(row):\n",
    "    return (row[\"f_vertical\"]**2 + row[\"f_horizontal\"]**2)**0.5\n",
    "    \n",
    "def for_range():\n",
    "    rtn = []\n",
    "    df = genDataFrame()\n",
    "    for row_idx in range(df.shape[0]):\n",
    "        row = df.iloc[row_idx]\n",
    "        rtn.append(pythagoras(row))\n",
    "    return pandas.Series(rtn)\n",
    "\n",
    "def for_iterrows():\n",
    "    rtn = []\n",
    "    df = genDataFrame()\n",
    "    for row_idx, row in df.iterrows():\n",
    "        rtn.append(pythagoras(row))\n",
    "    return pandas.Series(rtn)\n",
    "    \n",
    "def pandas_apply():\n",
    "    df = genDataFrame()\n",
    "    return df.apply(pythagoras, axis=1)# axis=1 means apply to rows\n",
    "\n",
    "repeats = 100\n",
    "gentime = timeit(genDataFrame, number=repeats)\n",
    "\n",
    "#Subtract gentime from each and multiply by 10 (for scaling to milliseconds) to get the time spent only on row iteration.\n",
    "print(f\"for_range: {timeit(for_range, number=repeats)*10-gentime:.2f}ms\")\n",
    "print(f\"for_iterrows: {timeit(for_iterrows, number=repeats)*10-gentime:.2f}ms\")\n",
    "print(f\"pandas_apply: {timeit(pandas_apply, number=repeats)*10-gentime:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97b075-04a3-40a2-a121-d13ff0f53009",
   "metadata": {},
   "source": [
    "## `apply()` is 4x faster than the two for approaches, as it avoids the Python for loop.\n",
    "#### But, we can do better by profiting from `vectorisation` and `broadcasting` and applying the mathematical operations on columns instead!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "003d088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorize: 0.02ms\n"
     ]
    }
   ],
   "source": [
    "# calculating pythagoras directly on the columns using numpy operations\n",
    "def vectorize():\n",
    "    df = genDataFrame()\n",
    "    return pandas.Series(numpy.sqrt(numpy.square(df[\"f_vertical\"]) + numpy.square(df[\"f_horizontal\"])))\n",
    "    \n",
    "print(f\"vectorize: {timeit(vectorize, number=repeats)-gentime:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440d8ec-2ddd-4740-8ece-906e41b9b0c7",
   "metadata": {},
   "source": [
    "### Ok, we were lucky here and we could profit from vectorisarion but it's not always the case!\n",
    "* An alternative approach is `converting your DataFrame` to a `Python dictionary` using `to_dict(orient='index')`.\n",
    "* This creates a nested dictionary, where each row of the outer dictionary is an internal dictionary.\n",
    "* This can then be processed via list-comprehension \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd73ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_dict: 80.74ms\n"
     ]
    }
   ],
   "source": [
    "def to_dict():\n",
    "    df = genDataFrame()\n",
    "    df_as_dict = df.to_dict(orient='index')\n",
    "    return pandas.Series([(r['f_vertical']**2 + r['f_horizontal']**2)**0.5 for r in df_as_dict.values()])\n",
    "\n",
    "print(f\"to_dict: {timeit(to_dict, number=repeats)*10-gentime:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e8d40ff-5e6c-4d1e-b343-4428808d256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f_vertical  f_horizontal\n",
      "0           1            10\n",
      "1           2            20\n",
      "2          23             3\n",
      "3           3            30\n",
      "4           5            50 {0: {'f_vertical': 1, 'f_horizontal': 10}, 1: {'f_vertical': 2, 'f_horizontal': 20}, 2: {'f_vertical': 23, 'f_horizontal': 3}, 3: {'f_vertical': 3, 'f_horizontal': 30}, 4: {'f_vertical': 5, 'f_horizontal': 50}}\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\n",
    "        \"f_vertical\": [1,2,23,3,5],\n",
    "        \"f_horizontal\": [10,20,3,30,50],\n",
    "        # todo some spurious columns\n",
    "    })\n",
    "df_as_dict = df.to_dict(orient='index')\n",
    "print(df, df_as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d0022-8e41-4310-8af1-07d677dd3b65",
   "metadata": {},
   "source": [
    "## Using dictionary (80ms) is slower than using vectorisation but is twice as fast as using `apply`.\n",
    "Note that indexing into `Pandas Series` (rows) is significantly slower than a `Python dictionary` as we will demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a26495a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 128.98ms\n",
      "dictionary: 2.12ms\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "import pandas as pandas\n",
    "\n",
    "N = 100000  # Number of rows in DataFrame\n",
    "\n",
    "def genInput():\n",
    "    s = pandas.Series({'a' : 1, 'b' : 2})\n",
    "    d = {'a' : 1, 'b' : 2}\n",
    "    return s, d\n",
    "\n",
    "def series():\n",
    "    s, _ = genInput()\n",
    "    for i in range(N):\n",
    "        y = s['a'] * s['b']\n",
    "\n",
    "def dictionary():\n",
    "    _, d = genInput()\n",
    "    for i in range(N):\n",
    "        y = d['a'] * d['b']\n",
    "\n",
    "repeats = 1000\n",
    "print(f\"series: {timeit(series, number=repeats):.2f}ms\")\n",
    "print(f\"dictionary: {timeit(dictionary, number=repeats):.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c394d9a-bf11-4295-804a-bc5f82976a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
